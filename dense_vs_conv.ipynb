{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 - Dense vs Convolutional\n",
        "\n",
        "## Data preprocessing\n",
        "The Fashion MNIST dataset is preprocessed for training neural networks. The images are reshaped from 2D (28x28 pixels) to 1D (784 pixels) and normalized to have pixel values between 0 and 1. The labels are converted from integer labels to one-hot vectors for multi-class classification."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: keras in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (2.11.0)\r\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(train_X, train_y), (test_X, test_y) = fashion_mnist.load_data()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1718119904575
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Convert the training and test labels to one-hot vectors\n",
        "train_y_cat = to_categorical(train_y, num_classes=10)\n",
        "test_y_cat = to_categorical(test_y, num_classes=10)\n",
        "\n",
        "# Preprocess the data for DENSE layers\n",
        "# Reshape the training and test images to 1D (flatten them) and normalize the pixel values (divide by 255)\n",
        "train_X_flat = train_X.reshape(train_X.shape[0], -1) / 255.0\n",
        "test_X_flat = test_X.reshape(test_X.shape[0], -1) / 255.0\n",
        "\n",
        "train_flat,valid_flat,train_label_flat,valid_label_flat = train_test_split(train_X_flat, train_y_cat, test_size=0.2, random_state=13)\n",
        "\n",
        "print('training set shape:', train_flat.shape)\n",
        "print('validation set shape:', valid_flat.shape)\n",
        "print('training label set shape:', train_label_flat.shape)\n",
        "print('validation label set shape:', valid_label_flat.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "training set shape: (48000, 784)\nvalidation set shape: (12000, 784)\ntraining label set shape: (48000, 10)\nvalidation label set shape: (12000, 10)\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718119918438
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data for Convolutional layers\n",
        "train_X = train_X.reshape(-1, 28, 28, 1)\n",
        "test_X = test_X.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Split train data for train and validation data!\n",
        "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_y_cat, test_size=0.2, random_state=13)\n",
        "\n",
        "print('training set shape:', train_X.shape)\n",
        "print('validation set shape:', valid_X.shape)\n",
        "print('training label set shape:', train_label.shape)\n",
        "print('validation label set shape:', valid_label.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "training set shape: (48000, 28, 28, 1)\nvalidation set shape: (12000, 28, 28, 1)\ntraining label set shape: (48000, 10)\nvalidation label set shape: (12000, 10)\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718119918663
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dense Model nr.1.\n",
        "\n",
        "The neural network model for multi-class classification is defined as follows:\n",
        "- simple feed-forward neural network with two hidden layers and one output layer\n",
        "- `Sequential` class: initializes the model, and it is used to add layers to the model\n",
        "- `Dense` class: creates fully connected layers, uses sigmoid as activation function\n",
        "- `SGD` class: specifies the stochastic gradient descent optimizer\n",
        "\n",
        "### Layer structure:\n",
        "- Input layer: it is made up of 784 nodes - one for each pixel in a 28x28 image\n",
        "- 1st hidden layer: 128 nodes, 'sigmoid' activation function and input shape of 784\n",
        "- 2nd hidden layer: 64 nodes, 'sigmoid' activation function\n",
        "- Output layer: 10 nodes (for the 10 classes) and 'softmax' activation function\n",
        "\n",
        "### Compile the model\n",
        "- with the use of the `compile()` function, the model is configured for training and sets the SGD optimizer, loss function, and metrics\n",
        "- `learning_rate = 0.01`\n",
        "- `loss='categorical_crossentropy'`\n",
        "\n",
        "### Train the model\n",
        "- fit the model to the training data for a fixed number of iterations\n",
        "- `epochs=10`\n",
        "- `batch_size=1000`\n",
        "\n",
        "### Model evaluation\n",
        "- compute the loss and the accuracy when compiling the model for the training and test data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries and modules\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Initialize a linear stack of layers\n",
        "model1 = Sequential()\n",
        "\n",
        "# 1st hidden layer\n",
        "model1.add(Dense(128, activation='sigmoid', input_shape=(784,)))\n",
        "\n",
        "# 2nd hidden layer\n",
        "model1.add(Dense(64, activation='sigmoid'))\n",
        "\n",
        "# Output layer\n",
        "model1.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(optimizer=SGD(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_model1 = model1.fit(train_flat, train_label_flat, epochs=10, batch_size=1000, validation_data=(valid_flat, valid_label_flat))\n",
        "\n",
        "# Evaluate the model on the training data\n",
        "train_loss, train_accuracy = model1.evaluate(train_flat, train_label_flat, verbose=0)\n",
        "\n",
        "# Print the training loss and accuracy\n",
        "print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model1.evaluate(test_X_flat, test_y_cat, verbose=0)\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024-06-11 15:29:19.384754: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/10\n48/48 [==============================] - 4s 12ms/step - loss: 2.3518 - accuracy: 0.1002 - val_loss: 2.3183 - val_accuracy: 0.0993\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/10\n48/48 [==============================] - 0s 7ms/step - loss: 2.3037 - accuracy: 0.1017 - val_loss: 2.2957 - val_accuracy: 0.1102\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/10\n48/48 [==============================] - 0s 7ms/step - loss: 2.2895 - accuracy: 0.1127 - val_loss: 2.2842 - val_accuracy: 0.1214\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/10\n48/48 [==============================] - 0s 7ms/step - loss: 2.2798 - accuracy: 0.1591 - val_loss: 2.2746 - val_accuracy: 0.2199\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/10\n48/48 [==============================] - 0s 7ms/step - loss: 2.2706 - accuracy: 0.2461 - val_loss: 2.2653 - val_accuracy: 0.2714\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/10\n48/48 [==============================] - 0s 7ms/step - loss: 2.2614 - accuracy: 0.2838 - val_loss: 2.2558 - val_accuracy: 0.3108\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/10\n48/48 [==============================] - 0s 7ms/step - loss: 2.2520 - accuracy: 0.3218 - val_loss: 2.2462 - val_accuracy: 0.3458\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/10\n48/48 [==============================] - 0s 6ms/step - loss: 2.2424 - accuracy: 0.3583 - val_loss: 2.2364 - val_accuracy: 0.3805\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/10\n48/48 [==============================] - 0s 7ms/step - loss: 2.2325 - accuracy: 0.3969 - val_loss: 2.2263 - val_accuracy: 0.4288\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/10\n48/48 [==============================] - 0s 7ms/step - loss: 2.2224 - accuracy: 0.4271 - val_loss: 2.2159 - val_accuracy: 0.4757\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTrain Loss: 2.2170, Train Accuracy: 0.4674\nTest Loss: 2.2167, Test Accuracy: 0.4627\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718119775900
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dense Model nr.2.\n",
        "\n",
        "For this training, the Sigmoid Activation functions is replaced with ReLu Activation which generally leads to faster convergence and better performance compared to Sigmoid.\n",
        "\n",
        "The neural network model for multi-class classification is defined as follows:\n",
        "- simple feed-forward neural network with two hidden layers and one output layer\n",
        "- `Sequential` class: initializes the model, and it is used to add layers to the model\n",
        "- `Dense` class: creates fully connected layers, uses ReLu as activation function\n",
        "- `SGD` class: specifies the stochastic gradient descent optimizer\n",
        "\n",
        "### Layer structure:\n",
        "- Input layer: it is made up of 784 nodes - one for each pixel in a 28x28 image\n",
        "- 1st hidden layer: 128 nodes, 'relu' activation function and input shape of 784\n",
        "- 2nd hidden layer: 64 nodes, 'relu' activation function\n",
        "- Output layer: 10 nodes (for the 10 classes) and 'softmax' activation function\n",
        "\n",
        "### Compile the model\n",
        "- with the use of the `compile()` function, the model is configured for training and sets the SGD optimizer, loss function, and metrics\n",
        "- `learning_rate = 0.01`\n",
        "- `loss='categorical_crossentropy'`\n",
        "\n",
        "### Train the model\n",
        "- fit the model to the training data for a fixed number of iterations\n",
        "- `epochs=10`\n",
        "- `batch_size=1000`\n",
        "\n",
        "### Model evaluation\n",
        "- compute the loss and the accuracy when compiling the model for the training and test data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a linear stack of layers\n",
        "model2 = Sequential()\n",
        "\n",
        "# 1st hidden layer\n",
        "model2.add(Dense(128, activation='relu', input_shape=(784,)))\n",
        "\n",
        "# 2nd hidden layer\n",
        "model2.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "model2.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model2.compile(optimizer=SGD(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_model2 = model2.fit(train_flat, train_label_flat, epochs=10, batch_size=1000, validation_data=(valid_flat, valid_label_flat))\n",
        "\n",
        "# Evaluate the model on the training data\n",
        "train_loss, train_accuracy = model2.evaluate(train_flat, train_label_flat, verbose=0)\n",
        "\n",
        "# Print the training loss and accuracy\n",
        "print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model2.evaluate(test_X_flat, test_y_cat, verbose=0)\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/10\n48/48 [==============================] - 1s 11ms/step - loss: 2.0448 - accuracy: 0.3881 - val_loss: 1.7235 - val_accuracy: 0.5842\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/10\n48/48 [==============================] - 0s 7ms/step - loss: 1.5149 - accuracy: 0.6173 - val_loss: 1.3219 - val_accuracy: 0.6397\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/10\n48/48 [==============================] - 0s 6ms/step - loss: 1.2029 - accuracy: 0.6515 - val_loss: 1.0943 - val_accuracy: 0.6634\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/10\n48/48 [==============================] - 0s 7ms/step - loss: 1.0294 - accuracy: 0.6733 - val_loss: 0.9689 - val_accuracy: 0.6853\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/10\n48/48 [==============================] - 0s 7ms/step - loss: 0.9283 - accuracy: 0.6933 - val_loss: 0.8919 - val_accuracy: 0.7037\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/10\n48/48 [==============================] - 0s 7ms/step - loss: 0.8617 - accuracy: 0.7137 - val_loss: 0.8376 - val_accuracy: 0.7245\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/10\n48/48 [==============================] - 0s 6ms/step - loss: 0.8132 - accuracy: 0.7320 - val_loss: 0.7961 - val_accuracy: 0.7387\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/10\n48/48 [==============================] - 0s 6ms/step - loss: 0.7756 - accuracy: 0.7459 - val_loss: 0.7643 - val_accuracy: 0.7467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/10\n48/48 [==============================] - 0s 6ms/step - loss: 0.7451 - accuracy: 0.7551 - val_loss: 0.7374 - val_accuracy: 0.7543\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/10\n48/48 [==============================] - 0s 7ms/step - loss: 0.7191 - accuracy: 0.7646 - val_loss: 0.7145 - val_accuracy: 0.7619\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTrain Loss: 0.7069, Train Accuracy: 0.7681\nTest Loss: 0.7257, Test Accuracy: 0.7559\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718119783399
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dense Model nr.3.\n",
        "\n",
        "The Dropout regularization prevents overfitting by randomly dropping out neurons during training. It is expected that the model performs better with these modifications due to improved generalization.\n",
        "\n",
        "The neural network model for multi-class classification is defined as follows:\n",
        "- simple feed-forward neural network with two hidden layers and one output layer\n",
        "- `Sequential` class: initializes the model, and it is used to add layers to the model\n",
        "- `Dense` class: creates fully connected layers, uses ReLu as activation function\n",
        "- `SGD` class: specifies the stochastic gradient descent optimizer\n",
        "- `Dropout` class: dropout regularization, which helps prevent overfitting by randomly setting a fraction of the input units to 0 during training\n",
        "\n",
        "### Layer structure:\n",
        "- Input layer: it is made up of 784 nodes - one for each pixel in a 28x28 image\n",
        "- Dropout layer: sets a fraction (0.2) of input units to 0 at each update\n",
        "- 1st hidden layer: 128 nodes, 'relu' activation function and input shape of 784\n",
        "- 2nd hidden layer: 64 nodes, 'relu' activation function\n",
        "- Dropout layer: sets a fraction (0.2) of input units to 0 at each update\n",
        "- Output layer: 10 nodes (for the 10 classes) and 'softmax' activation function\n",
        "\n",
        "### Compile the model\n",
        "- with the use of the `compile()` function, the model is configured for training and sets the SGD optimizer, loss function, and metrics\n",
        "- `learning_rate = 0.01`\n",
        "- `loss='categorical_crossentropy'`\n",
        "\n",
        "### Train the model\n",
        "- fit the model to the training data for a fixed number of iterations\n",
        "- `epochs=10`\n",
        "- `batch_size=1000`\n",
        "\n",
        "### Model evaluation\n",
        "- compute the loss and the accuracy when compiling the model for the training and test data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dropout\n",
        "\n",
        "# Initialize a linear stack of layers\n",
        "model3 = Sequential()\n",
        "\n",
        "# 1st hidden layer\n",
        "model3.add(Dense(128, activation='relu', input_shape=(784,)))\n",
        "model3.add(Dropout(0.2))\n",
        "# 2nd hidden layer\n",
        "model3.add(Dense(64, activation='relu'))\n",
        "model3.add(Dropout(0.2))\n",
        "\n",
        "# Output layer\n",
        "model3.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model3.compile(optimizer=SGD(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_model3 = model3.fit(train_flat, train_label_flat, epochs=10, batch_size=1000, validation_data=(valid_flat, valid_label_flat))\n",
        "\n",
        "# Evaluate the model on the training data\n",
        "train_loss, train_accuracy = model3.evaluate(train_flat, train_label_flat, verbose=0)\n",
        "\n",
        "# Print the training loss and accuracy\n",
        "print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model3.evaluate(test_X_flat, test_y_cat, verbose=0)\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/10\n48/48 [==============================] - 1s 11ms/step - loss: 2.1744 - accuracy: 0.2309 - val_loss: 1.9399 - val_accuracy: 0.4681\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/10\n48/48 [==============================] - 0s 8ms/step - loss: 1.8610 - accuracy: 0.4197 - val_loss: 1.6259 - val_accuracy: 0.5943\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/10\n48/48 [==============================] - 0s 7ms/step - loss: 1.6101 - accuracy: 0.4958 - val_loss: 1.3749 - val_accuracy: 0.6349\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/10\n48/48 [==============================] - 0s 7ms/step - loss: 1.4227 - accuracy: 0.5417 - val_loss: 1.1976 - val_accuracy: 0.6539\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/10\n48/48 [==============================] - 0s 7ms/step - loss: 1.2879 - accuracy: 0.5712 - val_loss: 1.0772 - val_accuracy: 0.6704\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/10\n48/48 [==============================] - 0s 7ms/step - loss: 1.1917 - accuracy: 0.5970 - val_loss: 0.9948 - val_accuracy: 0.6855\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/10\n48/48 [==============================] - 0s 7ms/step - loss: 1.1197 - accuracy: 0.6170 - val_loss: 0.9360 - val_accuracy: 0.6957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/10\n48/48 [==============================] - 0s 7ms/step - loss: 1.0622 - accuracy: 0.6328 - val_loss: 0.8913 - val_accuracy: 0.7066\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/10\n48/48 [==============================] - 0s 8ms/step - loss: 1.0172 - accuracy: 0.6488 - val_loss: 0.8552 - val_accuracy: 0.7183\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/10\n48/48 [==============================] - 0s 7ms/step - loss: 0.9819 - accuracy: 0.6580 - val_loss: 0.8260 - val_accuracy: 0.7262\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTrain Loss: 0.8175, Train Accuracy: 0.7281\nTest Loss: 0.8319, Test Accuracy: 0.7127\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718119817526
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional model nr.1.\n",
        "\n",
        "This model uses convolutional layers to extract features from the images.\n",
        "\n",
        "- `Sequential` class: creates a network, allows stacking layers sequentially\n",
        "- `Conv2D` class: extracts patterns from greyscale images\n",
        "- `Flatten` class: prepare output of convolutional layers for the fully connected layers\n",
        "- `Dense` class: creates fully connected layers\n",
        "- `SGD` class: specifies the stochastic gradient descent optimizer\n",
        "\n",
        "### Layer structure:\n",
        "- Input layer: takes input with shape (28, 28, 1)\n",
        "- 1st hidden layer: 32 nodes, 'sigmoid' activation function and input shape of (28, 28, 1)\n",
        "- 2nd hidden layer: 64 nodes, 'sigmoid' activation function\n",
        "- Dense layers: first one has 256 neurons, the second one has 128 neurons, both uses 'sigmoid' activation function\n",
        "- Output layer: 10 nodes (for the 10 classes) and 'softmax' activation function\n",
        "\n",
        "### Compile the model\n",
        "- with the use of the `compile()` function, the model is configured for training and sets the SGD optimizer, loss function, and metrics\n",
        "- `learning_rate = 0.001`\n",
        "- `loss='categorical_crossentropy'`\n",
        "\n",
        "### Train the model\n",
        "- fit the model to the training data for a fixed number of iterations\n",
        "- `epochs=10`\n",
        "- `batch_size=1000`\n",
        "\n",
        "### Model evaluation\n",
        "- compute the loss and the accuracy when compiling the model for the training and test data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Flatten, Dense\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Initialize the model\n",
        "model_cnn1 = Sequential()\n",
        "\n",
        "# Add convolutional layers\n",
        "model_cnn1.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid', input_shape=(28, 28, 1)))\n",
        "model_cnn1.add(Conv2D(64, kernel_size=(3, 3), activation='sigmoid'))\n",
        "\n",
        "# Flatten the output of the conv layers to feed into the dense layers\n",
        "model_cnn1.add(Flatten())\n",
        "\n",
        "# Add dense layers\n",
        "model_cnn1.add(Dense(256, activation='sigmoid'))\n",
        "model_cnn1.add(Dense(128, activation='sigmoid'))\n",
        "\n",
        "# Output layer with softmax activation for classification\n",
        "model_cnn1.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model_cnn1.compile(optimizer=SGD(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_cnn1 = model_cnn1.fit(train_X, train_label, epochs=10, batch_size=1000, validation_data=(valid_X, valid_label))\n",
        "\n",
        "# Evaluate the model on the training data\n",
        "train_loss_relu, train_accuracy_relu = model_cnn1.evaluate(train_X, train_label, verbose=0)\n",
        "\n",
        "# Print the training loss and accuracy\n",
        "print(f\"ReLU Train Loss: {train_loss_relu:.4f}, Train Accuracy: {train_accuracy_relu:.4f}\")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss_relu, test_accuracy_relu = model_cnn1.evaluate(test_X, test_y_cat, verbose=0)\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(f\"ReLU Test Loss: {test_loss_relu:.4f}, Test Accuracy: {test_accuracy_relu:.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/10\n48/48 [==============================] - 58s 1s/step - loss: 2.3312 - accuracy: 0.1136 - val_loss: 2.2956 - val_accuracy: 0.2187\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/10\n48/48 [==============================] - 57s 1s/step - loss: 2.2909 - accuracy: 0.2052 - val_loss: 2.2863 - val_accuracy: 0.1166\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/10\n48/48 [==============================] - 57s 1s/step - loss: 2.2804 - accuracy: 0.2699 - val_loss: 2.2744 - val_accuracy: 0.2576\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/10\n48/48 [==============================] - 58s 1s/step - loss: 2.2672 - accuracy: 0.3740 - val_loss: 2.2595 - val_accuracy: 0.4523\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/10\n48/48 [==============================] - 58s 1s/step - loss: 2.2500 - accuracy: 0.4316 - val_loss: 2.2397 - val_accuracy: 0.4532\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/10\n48/48 [==============================] - 59s 1s/step - loss: 2.2276 - accuracy: 0.4690 - val_loss: 2.2136 - val_accuracy: 0.4897\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/10\n48/48 [==============================] - 58s 1s/step - loss: 2.1980 - accuracy: 0.4913 - val_loss: 2.1797 - val_accuracy: 0.4798\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/10\n48/48 [==============================] - 43s 891ms/step - loss: 2.1592 - accuracy: 0.5037 - val_loss: 2.1351 - val_accuracy: 0.5227\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/10\n48/48 [==============================] - 31s 640ms/step - loss: 2.1085 - accuracy: 0.5390 - val_loss: 2.0779 - val_accuracy: 0.5466\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/10\n48/48 [==============================] - 31s 640ms/step - loss: 2.0443 - accuracy: 0.5631 - val_loss: 2.0064 - val_accuracy: 0.5738\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nReLU Train Loss: 2.0068, Train Accuracy: 0.5723\nReLU Test Loss: 2.0074, Test Accuracy: 0.5694\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718120453484
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional model nr.2.\n",
        "\n",
        "This model uses convolutional layers to extract features from the images. The Sigmoid Activation functions is replaced with ReLu Activation which generally leads to faster convergence and better performance compared to Sigmoid.\n",
        "\n",
        "- `Sequential` class: creates a network, allows stacking layers sequentially\n",
        "- `Conv2D` class: extracts patterns from greyscale images\n",
        "- `Flatten` class: prepare output of convolutional layers for the fully connected layers\n",
        "- `Dense` class: creates fully connected layers\n",
        "- `SGD` class: specifies the stochastic gradient descent optimizer\n",
        "\n",
        "### Layer structure:\n",
        "- Input layer: takes input with shape (28, 28, 1)\n",
        "- 1st hidden layer: 32 nodes, 'relu' activation function and input shape of (28, 28, 1)\n",
        "- 2nd hidden layer: 64 nodes, 'relu' activation function\n",
        "- Dense layers: first one has 256 neurons, the second one has 128 neurons, both uses 'relu' activation function\n",
        "- Output layer: 10 nodes (for the 10 classes) and 'softmax' activation function\n",
        "\n",
        "### Compile the model\n",
        "- with the use of the `compile()` function, the model is configured for training and sets the SGD optimizer, loss function, and metrics\n",
        "- `learning_rate = 0.001`\n",
        "- `loss='categorical_crossentropy'`\n",
        "\n",
        "### Train the model\n",
        "- fit the model to the training data for a fixed number of iterations\n",
        "- `epochs=10`\n",
        "- `batch_size=1000`\n",
        "\n",
        "### Model evaluation\n",
        "- compute the loss and the accuracy when compiling the model for the training and test data\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "\n",
        "# Initialize the model\n",
        "model_cnn2 = Sequential()\n",
        "\n",
        "# Add convolutional layers\n",
        "model_cnn2.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model_cnn2.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "\n",
        "# Flatten the output of the conv layers to feed into the dense layers\n",
        "model_cnn2.add(Flatten())\n",
        "\n",
        "# Add dense layers\n",
        "model_cnn2.add(Dense(256, activation='relu'))\n",
        "model_cnn2.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Output layer with softmax activation for classification\n",
        "model_cnn2.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model_cnn2.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_cnn2 = model_cnn2.fit(train_X, train_label, epochs=10, batch_size=1000, validation_data=(valid_X, valid_label))\n",
        "\n",
        "# Evaluate the model on the training data\n",
        "train_loss_relu, train_accuracy_relu = model_cnn2.evaluate(train_X, train_label, verbose=0)\n",
        "\n",
        "# Print the training loss and accuracy\n",
        "print(f\"ReLU Train Loss: {train_loss_relu:.4f}, Train Accuracy: {train_accuracy_relu:.4f}\")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss_relu, test_accuracy_relu = model_cnn2.evaluate(test_X, test_y_cat, verbose=0)\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(f\"ReLU Test Loss: {test_loss_relu:.4f}, Test Accuracy: {test_accuracy_relu:.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/10\n48/48 [==============================] - 30s 625ms/step - loss: 3.5469 - accuracy: 0.5789 - val_loss: 0.7144 - val_accuracy: 0.7536\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/10\n48/48 [==============================] - 30s 622ms/step - loss: 0.6493 - accuracy: 0.7741 - val_loss: 0.6070 - val_accuracy: 0.7916\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/10\n48/48 [==============================] - 30s 617ms/step - loss: 0.5527 - accuracy: 0.8056 - val_loss: 0.5522 - val_accuracy: 0.8075\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/10\n48/48 [==============================] - 30s 621ms/step - loss: 0.5044 - accuracy: 0.8223 - val_loss: 0.5125 - val_accuracy: 0.8227\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/10\n48/48 [==============================] - 29s 615ms/step - loss: 0.4751 - accuracy: 0.8332 - val_loss: 0.4891 - val_accuracy: 0.8289\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/10\n48/48 [==============================] - 30s 628ms/step - loss: 0.4494 - accuracy: 0.8409 - val_loss: 0.4569 - val_accuracy: 0.8403\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/10\n48/48 [==============================] - 30s 623ms/step - loss: 0.4188 - accuracy: 0.8516 - val_loss: 0.4412 - val_accuracy: 0.8443\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/10\n48/48 [==============================] - 30s 617ms/step - loss: 0.4123 - accuracy: 0.8543 - val_loss: 0.4613 - val_accuracy: 0.8354\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/10\n48/48 [==============================] - 30s 622ms/step - loss: 0.3949 - accuracy: 0.8610 - val_loss: 0.4203 - val_accuracy: 0.8527\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/10\n48/48 [==============================] - 30s 618ms/step - loss: 0.3761 - accuracy: 0.8685 - val_loss: 0.4134 - val_accuracy: 0.8542\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nReLU Train Loss: 0.3617, Train Accuracy: 0.8738\nReLU Test Loss: 0.4343, Test Accuracy: 0.8518\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718121201744
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional model nr.3.\n",
        "\n",
        "This model uses convolutional layers to extract features from the images. The Dropout layers help prevent overfitting by randomly setting a fraction of input units to 0 at each update during training.\n",
        "\n",
        "- `Sequential` class: creates a network, allows stacking layers sequentially\n",
        "- `Conv2D` class: extracts patterns from greyscale images\n",
        "- `Flatten` class: prepare output of convolutional layers for the fully connected layers\n",
        "- `Dense` class: creates fully connected layers\n",
        "- `SGD` class: specifies the stochastic gradient descent optimizer\n",
        "- `Dropout` class: dropout regularization, which helps prevent overfitting by randomly setting a fraction of the input units to 0 during training\n",
        "\n",
        "### Layer structure:\n",
        "- Input layer: takes input with shape (28, 28, 1)\n",
        "- 1st hidden layer: 32 nodes, 'relu' activation function and input shape of (28, 28, 1)\n",
        "- 2nd hidden layer: 64 nodes, 'relu' activation function\n",
        "- Dense layers: first one has 256 neurons, the second one has 128 neurons, both uses 'relu' activation function\n",
        "- Dropout layer: sets a fraction (0.5) of input units to 0 at each update\n",
        "- Output layer: 10 nodes (for the 10 classes) and 'softmax' activation function\n",
        "\n",
        "### Compile the model\n",
        "- with the use of the `compile()` function, the model is configured for training and sets SGD the optimizer, loss function, and metrics\n",
        "- `learning_rate = 0.001`\n",
        "- `loss='categorical_crossentropy'`\n",
        "\n",
        "### Train the model\n",
        "- fit the model to the training data for a fixed number of iterations\n",
        "- `epochs=10`\n",
        "- `batch_size=1000`\n",
        "\n",
        "### Model evaluation\n",
        "- compute the loss and the accuracy when compiling the model for the training and test data\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, Dropout\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Initialize the model\n",
        "model_cnn3 = Sequential()\n",
        "\n",
        "# Add convolutional layers\n",
        "model_cnn3.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model_cnn3.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "\n",
        "# Flatten the output of the conv layers to feed into the dense layers\n",
        "model_cnn3.add(Flatten())\n",
        "\n",
        "# Add dense layers\n",
        "model_cnn3.add(Dense(256, activation='relu'))\n",
        "model_cnn3.add(Dropout(0.5))\n",
        "model_cnn3.add(Dense(128, activation='relu'))\n",
        "model_cnn3.add(Dropout(0.5))\n",
        "\n",
        "# Output layer with softmax activation for classification\n",
        "model_cnn3.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model_cnn3.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_cnn3 = model_cnn3.fit(train_X, train_label, epochs=10, batch_size=1000, validation_data=(valid_X, valid_label))\n",
        "\n",
        "# Evaluate the model on the training data\n",
        "train_loss_relu, train_accuracy_relu = model_cnn3.evaluate(train_X, train_label, verbose=0)\n",
        "\n",
        "# Print the training loss and accuracy\n",
        "print(f\"ReLU Train Loss: {train_loss_relu:.4f}, Train Accuracy: {train_accuracy_relu:.4f}\")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss_relu, test_accuracy_relu = model_cnn3.evaluate(test_X, test_y_cat, verbose=0)\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(f\"ReLU Test Loss: {test_loss_relu:.4f}, Test Accuracy: {test_accuracy_relu:.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/10\n48/48 [==============================] - 31s 643ms/step - loss: 2.9542 - accuracy: 0.3405 - val_loss: 1.1232 - val_accuracy: 0.6975\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/10\n48/48 [==============================] - 32s 659ms/step - loss: 1.5593 - accuracy: 0.4800 - val_loss: 0.9084 - val_accuracy: 0.7482\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/10\n48/48 [==============================] - 31s 645ms/step - loss: 1.3841 - accuracy: 0.5439 - val_loss: 0.8364 - val_accuracy: 0.7667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/10\n48/48 [==============================] - 30s 626ms/step - loss: 1.2720 - accuracy: 0.5825 - val_loss: 0.7471 - val_accuracy: 0.7825\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/10\n48/48 [==============================] - 30s 617ms/step - loss: 1.1914 - accuracy: 0.6121 - val_loss: 0.7120 - val_accuracy: 0.7943\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/10\n48/48 [==============================] - 30s 621ms/step - loss: 1.1213 - accuracy: 0.6360 - val_loss: 0.6764 - val_accuracy: 0.8046\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/10\n48/48 [==============================] - 30s 617ms/step - loss: 1.0779 - accuracy: 0.6504 - val_loss: 0.6500 - val_accuracy: 0.8062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/10\n48/48 [==============================] - 30s 622ms/step - loss: 1.0233 - accuracy: 0.6682 - val_loss: 0.6202 - val_accuracy: 0.8165\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/10\n48/48 [==============================] - 30s 625ms/step - loss: 0.9822 - accuracy: 0.6814 - val_loss: 0.6102 - val_accuracy: 0.8183\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/10\n48/48 [==============================] - 30s 620ms/step - loss: 0.9559 - accuracy: 0.6902 - val_loss: 0.5854 - val_accuracy: 0.8219\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nReLU Train Loss: 0.5543, Train Accuracy: 0.8324\nReLU Test Loss: 0.5823, Test Accuracy: 0.8216\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718121520925
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
